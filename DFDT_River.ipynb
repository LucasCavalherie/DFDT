{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LucasCavalherie/DFDT/blob/main/DFDT_River.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install river"
      ],
      "metadata": {
        "id": "HoAlwxVJ1S6R"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Imports\n",
        "import math\n",
        "import random\n",
        "import csv\n",
        "import time\n",
        "import os\n",
        "import itertools\n",
        "from collections import defaultdict\n",
        "from river import base, metrics, evaluate\n",
        "\n",
        "def calculate_gini_impurity(class_distribution):\n",
        "    \"\"\"Calculates the Gini Impurity for a class distribution.\"\"\"\n",
        "    total_count = sum(class_distribution.values())\n",
        "    if total_count == 0:\n",
        "        return 0.0\n",
        "\n",
        "    impurity = 1.0\n",
        "    for count in class_distribution.values():\n",
        "        probability = count / total_count\n",
        "        impurity -= probability ** 2\n",
        "    return impurity\n",
        "\n",
        "class NumericAttributeSplitter:\n",
        "    \"\"\"\n",
        "    This class stores statistics for a single numeric attribute\n",
        "    and finds the best split point for it.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self._value_class_observations = defaultdict(list)\n",
        "\n",
        "    def update(self, value, class_label):\n",
        "        \"\"\"Updates the splitter with a new value and its class.\"\"\"\n",
        "        self._value_class_observations[value].append(class_label)\n",
        "\n",
        "    def get_best_split(self, parent_impurity):\n",
        "        \"\"\"\n",
        "        Finds the best split point for this attribute.\n",
        "        It tests all midpoints between unique values as split candidates.\n",
        "        \"\"\"\n",
        "        best_split_value = None\n",
        "        best_gain = -1.0\n",
        "        sorted_unique_values = sorted(self._value_class_observations.keys())\n",
        "        if len(sorted_unique_values) < 2:\n",
        "            return None, -1.0\n",
        "        for i in range(len(sorted_unique_values) - 1):\n",
        "            split_candidate = (sorted_unique_values[i] + sorted_unique_values[i+1]) / 2\n",
        "            left_branch_dist = defaultdict(int)\n",
        "            right_branch_dist = defaultdict(int)\n",
        "            for value, classes in self._value_class_observations.items():\n",
        "                for c in classes:\n",
        "                    if value <= split_candidate:\n",
        "                        left_branch_dist[c] += 1\n",
        "                    else:\n",
        "                        right_branch_dist[c] += 1\n",
        "            left_count = sum(left_branch_dist.values())\n",
        "            right_count = sum(right_branch_dist.values())\n",
        "            total_count = left_count + right_count\n",
        "            if left_count == 0 or right_count == 0:\n",
        "                continue\n",
        "            left_impurity = calculate_gini_impurity(left_branch_dist)\n",
        "            right_impurity = calculate_gini_impurity(right_branch_dist)\n",
        "            weighted_children_impurity = (left_count / total_count) * left_impurity + \\\n",
        "                                         (right_count / total_count) * right_impurity\n",
        "            gain = parent_impurity - weighted_children_impurity\n",
        "            if gain > best_gain:\n",
        "                best_gain = gain\n",
        "                best_split_value = split_candidate\n",
        "        return best_split_value, best_gain\n",
        "\n",
        "class Node:\n",
        "    \"\"\"Represents a node in the decision tree with learning capabilities.\"\"\"\n",
        "    def __init__(self, is_leaf=True, parent=None, depth=0):\n",
        "        self.is_leaf = is_leaf\n",
        "        self.parent = parent\n",
        "        self.depth = depth\n",
        "        self.children = {}\n",
        "        self.active = True\n",
        "        self.id = random.randint(0, 1000000)\n",
        "        self.class_distribution = defaultdict(int)\n",
        "        self.feature_estimators = defaultdict(NumericAttributeSplitter)\n",
        "        self.n_l = 0\n",
        "        self.n_check_l = 0\n",
        "        self.n_leaf_l = 0\n",
        "        self.n_tree_l = 0\n",
        "        self.split_attribute = None\n",
        "        self.split_value = None\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"Node(id={self.id}, is_leaf={self.is_leaf}, active={self.active}, n_l={self.n_l}, dist={self.class_distribution})\"\n",
        "\n",
        "    def get_prediction(self):\n",
        "        if not self.class_distribution: return None\n",
        "        return max(self.class_distribution, key=self.class_distribution.get)\n",
        "\n",
        "    def update_stats(self, instance_X, instance_y):\n",
        "        self.class_distribution[instance_y] += 1\n",
        "        for attr_index, value in instance_X.items():\n",
        "            self.feature_estimators[attr_index].update(value, instance_y)\n",
        "\n",
        "class DFDT(base.Classifier):\n",
        "    \"\"\"\n",
        "    Implementation of the Dynamic Fast Decision Tree (DFDT) algorithm,\n",
        "    made compatible with the River API.\n",
        "    \"\"\"\n",
        "    def __init__(self, delta=0.05, initial_grace_period=100,\n",
        "                 grow_fast_threshold=2.0, deactivate_threshold=0.2,\n",
        "                 std_dev_multiplier_c3_c4=1.0, std_dev_multiplier_c5=1.0,\n",
        "                 r_heuristic_range=0.5):\n",
        "        self.delta = delta\n",
        "        self.initial_grace_period = initial_grace_period\n",
        "        self.grow_fast_threshold = grow_fast_threshold\n",
        "        self.deactivate_threshold = deactivate_threshold\n",
        "        self.std_dev_multiplier_c3_c4 = std_dev_multiplier_c3_c4\n",
        "        self.std_dev_multiplier_c5 = std_dev_multiplier_c5\n",
        "        self.R_HEURISTIC_RANGE = r_heuristic_range\n",
        "\n",
        "        self.root = Node(is_leaf=True, depth=0)\n",
        "        self.root.n_min_grace_period = self.initial_grace_period\n",
        "        self.leaves = {self.root}\n",
        "        self.h_stat_values, self.g_stat_values, self.n_stat_values, self.hb_stat_values = [], [], [], []\n",
        "        self.n_total_instances = 0\n",
        "\n",
        "    @property\n",
        "    def _supervised(self):\n",
        "        return True\n",
        "\n",
        "    def learn_one(self, x, y):\n",
        "        \"\"\"Treina o modelo com uma única instância, conforme a API do River.\"\"\"\n",
        "        leaf = self._route_to_leaf(x)\n",
        "        leaf.update_stats(x, y)\n",
        "        self.n_total_instances += 1\n",
        "        leaf.n_l += 1\n",
        "        self._attempt_growth(leaf, self.n_total_instances)\n",
        "        return self\n",
        "\n",
        "    def predict_one(self, x):\n",
        "        \"\"\"Prevê o rótulo de uma única instância, conforme a API do River.\"\"\"\n",
        "        return self.predict(x)\n",
        "\n",
        "    def _avg(self, values_list):\n",
        "        return sum(values_list) / len(values_list) if values_list else 0\n",
        "\n",
        "    def _std_dev(self, values_list):\n",
        "        if not values_list or len(values_list) < 2: return 0\n",
        "        mean = self._avg(values_list)\n",
        "        variance = sum([(x - mean) ** 2 for x in values_list]) / (len(values_list) - 1)\n",
        "        return math.sqrt(variance)\n",
        "\n",
        "    def _route_to_leaf(self, instance_X):\n",
        "        current_node = self.root\n",
        "        while not current_node.is_leaf:\n",
        "            if current_node.split_attribute is None or current_node.split_value is None: break\n",
        "            instance_value = instance_X.get(current_node.split_attribute, 0)\n",
        "            branch_index = 0 if instance_value <= current_node.split_value else 1\n",
        "            if branch_index in current_node.children: current_node = current_node.children[branch_index]\n",
        "            else: break\n",
        "        return current_node\n",
        "\n",
        "    def predict(self, instance_X):\n",
        "        leaf = self._route_to_leaf(instance_X)\n",
        "        return leaf.get_prediction()\n",
        "\n",
        "    def _attempt_growth(self, leaf, n_total_instances):\n",
        "        if not leaf.active: return\n",
        "        fraction = ((leaf.n_l - leaf.n_leaf_l) * len(self.leaves)) / (n_total_instances - leaf.n_tree_l) if n_total_instances - leaf.n_tree_l > 0 else 0\n",
        "        grow_fast_flag = fraction > self.grow_fast_threshold\n",
        "        if fraction < self.deactivate_threshold:\n",
        "            leaf.active = False\n",
        "            return\n",
        "        if not hasattr(leaf, 'n_min_grace_period'): leaf.n_min_grace_period = self.initial_grace_period\n",
        "        is_ready_for_check = (leaf.n_l - leaf.n_check_l > leaf.n_min_grace_period)\n",
        "        if len(leaf.class_distribution) > 1 and is_ready_for_check:\n",
        "            epsilon = self._calculate_hoeffding_bound(leaf.n_l)\n",
        "            g_values = self._calculate_g_values(leaf)\n",
        "            if self._can_split(leaf, grow_fast_flag, g_values, epsilon):\n",
        "                self._split_leaf(leaf)\n",
        "            else:\n",
        "                leaf.n_check_l = leaf.n_l\n",
        "                self._adapt_grace_period(leaf, g_values, epsilon)\n",
        "\n",
        "    def _split_leaf(self, leaf):\n",
        "        leaf.is_leaf = False\n",
        "        leaf.active = False\n",
        "        self.leaves.remove(leaf)\n",
        "        split_attr, split_val = leaf.best_split_info['attribute'], leaf.best_split_info['split_value']\n",
        "        leaf.split_attribute, leaf.split_value = split_attr, split_val\n",
        "        left_child, right_child = Node(is_leaf=True, parent=leaf, depth=leaf.depth + 1), Node(is_leaf=True, parent=leaf, depth=leaf.depth + 1)\n",
        "        for attr, splitter in leaf.feature_estimators.items():\n",
        "            for val, classes in splitter._value_class_observations.items():\n",
        "                for cls in classes:\n",
        "                    target_child = left_child if val <= split_val else right_child\n",
        "                    target_child.update_stats({attr: val}, cls)\n",
        "        self.leaves.add(left_child)\n",
        "        self.leaves.add(right_child)\n",
        "        leaf.children[0], leaf.children[1] = left_child, right_child\n",
        "\n",
        "    def _can_split(self, leaf, grow_fast, g_values, epsilon):\n",
        "        if not g_values: return False\n",
        "        sorted_g = sorted(g_values.items(), key=lambda item: item[1], reverse=True)\n",
        "        if not sorted_g: return False\n",
        "        g_best_attr, g_best_val = sorted_g[0]\n",
        "        g_second_best_val = sorted_g[1][1] if len(sorted_g) > 1 else 0\n",
        "        avg_hb_hist = self._avg(self.hb_stat_values) if self.hb_stat_values else float('inf')\n",
        "        if not ((g_best_val - g_second_best_val >= epsilon) or (epsilon < avg_hb_hist)): return False\n",
        "        impurity = calculate_gini_impurity(leaf.class_distribution)\n",
        "        if grow_fast: return True\n",
        "        current_impurities = [calculate_gini_impurity(n.class_distribution) for n in self.leaves if n.active]\n",
        "        c3 = impurity >= self._avg(current_impurities) - (self.std_dev_multiplier_c3_c4 * self._std_dev(current_impurities))\n",
        "        c4 = impurity >= self._avg(self.h_stat_values) - (self.std_dev_multiplier_c3_c4 * self._std_dev(self.h_stat_values))\n",
        "        c5 = g_best_val >= self._avg(self.g_stat_values) - (self.std_dev_multiplier_c5 * self._std_dev(self.g_stat_values))\n",
        "        c6 = leaf.n_l >= self._avg(self.n_stat_values)\n",
        "        if c3 and c4 and c5 and c6:\n",
        "            self._update_historical_stats(impurity, g_best_val, leaf.n_l, epsilon)\n",
        "            best_split_val, _ = leaf.feature_estimators[g_best_attr].get_best_split(impurity)\n",
        "            leaf.best_split_info = {'attribute': g_best_attr, 'split_value': best_split_val}\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    def _adapt_grace_period(self, leaf, g_values, epsilon):\n",
        "        sorted_g = sorted(g_values.values(), reverse=True)\n",
        "        g_best, g_second_best = (sorted_g[0] if sorted_g else 0), (sorted_g[1] if len(sorted_g) > 1 else 0)\n",
        "        delta_g = g_best - g_second_best\n",
        "        avg_hb = self._avg(self.hb_stat_values) if self.hb_stat_values else epsilon\n",
        "        new_n_min = 0\n",
        "        if delta_g < epsilon and delta_g > avg_hb and delta_g > 1e-9: new_n_min = math.ceil((self.R_HEURISTIC_RANGE**2 * math.log(1 / self.delta)) / (2 * delta_g**2))\n",
        "        elif delta_g < avg_hb and epsilon > avg_hb and avg_hb > 1e-9: new_n_min = math.ceil((self.R_HEURISTIC_RANGE**2 * math.log(1 / self.delta)) / (2 * avg_hb**2))\n",
        "        if new_n_min > 0: leaf.n_min_grace_period = max(leaf.n_min_grace_period, new_n_min)\n",
        "\n",
        "    def _calculate_g_values(self, leaf):\n",
        "        gains = {}\n",
        "        parent_impurity = calculate_gini_impurity(leaf.class_distribution)\n",
        "        for attr_index, splitter in leaf.feature_estimators.items():\n",
        "            _, gain = splitter.get_best_split(parent_impurity)\n",
        "            if gain > 0: gains[attr_index] = gain\n",
        "        return gains\n",
        "\n",
        "    def _calculate_hoeffding_bound(self, n):\n",
        "        if n == 0: return float('inf')\n",
        "        return math.sqrt((self.R_HEURISTIC_RANGE**2 * math.log(1 / self.delta)) / (2 * n))\n",
        "\n",
        "    def _update_historical_stats(self, impurity, g_best, n_l, epsilon):\n",
        "        self.h_stat_values.append(impurity); self.g_stat_values.append(g_best); self.n_stat_values.append(n_l); self.hb_stat_values.append(epsilon)\n",
        "\n",
        "def load_csv_dataset(file_path, class_index=-1):\n",
        "    \"\"\"Loads a dataset from a local CSV file into a list.\"\"\"\n",
        "    stream = []\n",
        "    try:\n",
        "        with open(file_path, 'r', newline='') as f:\n",
        "            reader = csv.reader(f)\n",
        "            try:\n",
        "                next(reader)\n",
        "            except StopIteration:\n",
        "                return []\n",
        "            for row in reader:\n",
        "                try:\n",
        "                    if class_index < 0:\n",
        "                        effective_class_index = len(row) + class_index\n",
        "                    else:\n",
        "                        effective_class_index = class_index\n",
        "\n",
        "\n",
        "                    try:\n",
        "                        label = int(row[effective_class_index])\n",
        "                    except ValueError:\n",
        "                        label = row[effective_class_index]\n",
        "\n",
        "                    features_list = [float(val) for i, val in enumerate(row) if i != effective_class_index]\n",
        "                    instance_X_dict = {j: features_list[j] for j in range(len(features_list))}\n",
        "                    stream.append((instance_X_dict, label))\n",
        "                except (ValueError, IndexError):\n",
        "                    continue\n",
        "        return stream\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: File not found at '{file_path}'.\")\n",
        "        return None\n",
        "\n",
        "def set_results_log(filepath, dataset_name, accuracy, exec_time, params=None):\n",
        "    \"\"\"Logs the results of an experiment to a file.\"\"\"\n",
        "    result_line = f\"{dataset_name},{exec_time:.2f},{accuracy*100:.4f},{params if params else 'N/A'}\\n\"\n",
        "    write_header = not os.path.exists(filepath)\n",
        "    with open(filepath, 'a') as f:\n",
        "        if write_header:\n",
        "            f.write(\"Dataset,Execution Time (s),Final Accuracy (%),Parameters\\n\")\n",
        "        f.write(result_line)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    print(\"DFDT Python Implementation - River-based Grid Search Runner\")\n",
        "    print(\"=\" * 40)\n",
        "\n",
        "    datasets = [\n",
        "        {'name': 'NOAA', 'path': 'NOAA.csv', 'class_index': 8},\n",
        "        {'name': 'Keystroke', 'path': 'Keystroke.csv', 'class_index': 10},\n",
        "        {'name': 'Chess', 'path': 'Chess.csv', 'class_index': 7},\n",
        "        {'name': 'Luxembourg', 'path': 'Luxembourg.csv', 'class_index': 31},\n",
        "        {'name': 'Ozone', 'path': 'Ozone.csv', 'class_index': 72},\n",
        "        {'name': 'SmartMeter', 'path': 'SmartMeter.csv', 'class_index': 96},\n",
        "        {'name': 'Electricity', 'path': 'Electricity.csv', 'class_index': 8},\n",
        "        {'name': 'Rialto', 'path': 'Rialto.csv', 'class_index': 27},\n",
        "        {'name': 'Forest', 'path': 'Forest.csv', 'class_index': 54},\n",
        "        {'name': 'Posture', 'path': 'Posture.csv', 'class_index': 3},\n",
        "        {'name': 'PokerHand', 'path': 'PokerHand.csv', 'class_index': 10},\n",
        "    ]\n",
        "\n",
        "    param_grid = {\n",
        "        'delta': [0.05],\n",
        "        'initial_grace_period': [200, 300, 400],\n",
        "        'grow_fast_threshold': [1.5],\n",
        "        'deactivate_threshold': [0.1],\n",
        "        'std_dev_multiplier_c3_c4': [0.5],\n",
        "        'std_dev_multiplier_c5': [0.5],\n",
        "        'r_heuristic_range': [0.45]\n",
        "    }\n",
        "\n",
        "    results_filepath = 'dfdt_river_grid_search_results.csv'\n",
        "    if os.path.exists(results_filepath):\n",
        "        os.remove(results_filepath)\n",
        "\n",
        "    # Loop principal para a pesquisa em grelha\n",
        "    for config in datasets:\n",
        "        print(f\"\\n{'='*40}\")\n",
        "        print(f\"Processing dataset: {config['name']}\")\n",
        "\n",
        "        data_stream = load_csv_dataset(config['path'], config['class_index'])\n",
        "        if not data_stream:\n",
        "            print(f\"Could not load or empty dataset: {config['name']}. Skipping.\")\n",
        "            continue\n",
        "\n",
        "        keys, values = zip(*param_grid.items())\n",
        "        param_combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
        "\n",
        "        print(f\"Starting Grid Search with {len(param_combinations)} combinations.\")\n",
        "\n",
        "        for i, params in enumerate(param_combinations):\n",
        "            model = DFDT(**params)\n",
        "            metric = metrics.Accuracy()\n",
        "\n",
        "            start_time = time.time()\n",
        "\n",
        "            evaluate.progressive_val_score(dataset=data_stream, model=model, metric=metric, print_every=0)\n",
        "\n",
        "            end_time = time.time()\n",
        "            execution_time = end_time - start_time\n",
        "\n",
        "            print(f\"  [Combination {i+1}/{len(param_combinations)}] Accuracy: {metric.get()*100:.4f}% | Time: {execution_time:.2f}s\")\n",
        "            set_results_log(results_filepath, config['name'], metric.get(), execution_time, params)\n",
        "\n",
        "    print(f\"\\n{'=' * 40}\")\n",
        "    print(\"Processing complete!\")\n",
        "    print(f\"All results saved to '{results_filepath}'.\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DFDT Python Implementation - River-based Grid Search Runner\n",
            "========================================\n",
            "\n",
            "========================================\n",
            "Processing dataset: Forest\n",
            "Starting Grid Search with 3 combinations.\n",
            "  [Combination 1/3] Accuracy: 48.7594% | Time: 41.95s\n",
            "  [Combination 2/3] Accuracy: 48.7594% | Time: 41.68s\n",
            "  [Combination 3/3] Accuracy: 63.1086% | Time: 42.00s\n",
            "\n",
            "========================================\n",
            "Processing dataset: Posture\n",
            "Starting Grid Search with 3 combinations.\n",
            "  [Combination 1/3] Accuracy: 33.0458% | Time: 5.97s\n",
            "  [Combination 2/3] Accuracy: 33.0458% | Time: 3.22s\n",
            "  [Combination 3/3] Accuracy: 33.0458% | Time: 3.63s\n",
            "\n",
            "========================================\n",
            "Processing dataset: PokerHand\n",
            "Starting Grid Search with 3 combinations.\n",
            "  [Combination 1/3] Accuracy: 49.9642% | Time: 18.33s\n",
            "  [Combination 2/3] Accuracy: 52.5279% | Time: 19.90s\n",
            "  [Combination 3/3] Accuracy: 49.9749% | Time: 18.36s\n",
            "\n",
            "========================================\n",
            "Processing complete!\n",
            "All results saved to 'dfdt_river_grid_search_results.csv'.\n"
          ]
        }
      ],
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRikolhb1A4k",
        "outputId": "861f52ec-a30d-4a2c-abc1-45105878df74"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}